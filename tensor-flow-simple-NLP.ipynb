{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Notebook criado por: Lorena M. Santos. Você pode salvar uma cópia se quiser, clicando em File --> Save a Copy in Drive."
      ],
      "metadata": {
        "id": "5ug3H-JTawdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando um Classificador de Sentimentos Simples usando TensorFlow\n",
        "\n",
        "Neste exemplo, criamos um classificador de sentimentos básico usando TensorFlow. O modelo recebe frases de entrada e determina se elas têm um sentimento positivo ou negativo, utilizando uma abordagem simples de embedding e redes neurais densas.\n",
        "\n",
        "## O Que Este Modelo Faz?\n",
        "O modelo aqui desenvolvido converte as palavras em vetores numéricos (usando a camada Embedding).\n",
        "\n",
        "Com base nesses vetores, o modelo aprende a identificar padrões associados a frases positivas ou negativas.\n",
        "\n",
        "Ele prevê um valor entre 0 e 1:\n",
        "- Valores acima de 0.5 são considerados positivos.\n",
        "- Valores abaixo de 0.5 são considerados negativos.\n",
        "\n",
        "Esse modelo é **simples** e foi treinado do zero em um pequeno conjunto de dados. **Ele serve como uma introdução à construção de modelos de NLP** e pode ser expandido para conjuntos de dados maiores e mais complexos.\n",
        "\n",
        "O intuito é demonstrar um pouco como o TensorFlow é utilizado em tarefas de deep learnig, mostrando suas bibliotecas, e como este framework facilita a implementação de códigos relacionados à uma tarefa de NLP, por exemplo."
      ],
      "metadata": {
        "id": "qiivdAnxHySO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Primeiro Passo: Importando Biblliotecas\n",
        "\n",
        "- TensorFlow: Biblioteca de aprendizado de máquina amplamente utilizada para deep learning.\n",
        "- Keras: API de alto nível do TensorFlow para criação de modelos.\n",
        "- Tokenizer: Converte textos em sequências de números.\n",
        "- pad_sequences: Garante que todas as sequências tenham o mesmo tamanho, preenchendo com zeros quando necessário."
      ],
      "metadata": {
        "id": "hcDwN3DBIIp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "38ym9egCVywk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando as Sentenças e Labels\n",
        "\n",
        "Aqui, criamos:\n",
        "\n",
        "- Sentenças: Uma lista simples de frases para treino (positivo/negativo).\n",
        "- Labels: Rótulos binários representando o sentimento (1 para positivo, 0 para negativo)."
      ],
      "metadata": {
        "id": "2RG_6_OWIhGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Dados simples\n",
        "sentences = [\n",
        "    \"Eu amo programação\",\n",
        "    \"Este filme é terrível\",\n",
        "    \"O dia está lindo\",\n",
        "    \"Eu detesto esperar\",\n",
        "    \"Que lugar maravilhoso!\",\n",
        "    \"Isso é uma perda de tempo\"\n",
        "]\n",
        "labels = [1, 0, 1, 0, 1, 0]  # 1 = positivo, 0 = negativo"
      ],
      "metadata": {
        "id": "Zebj8NNRV2WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessamento dos Dados\n",
        "\n",
        "Para o pre-processamento, temos:\n",
        "\n",
        "- Tokenizer: Converte cada palavra em um número único (token).\n",
        "- `num_words=1000:` Considera as 1000 palavras mais comuns.\n",
        "- `oov_token=\"<OOV>\"`: Define um token para palavras fora do vocabulário.\n",
        "- `texts_to_sequences`: Transforma as frases em listas de tokens.\n",
        "- `pad_sequences`: Preenche as listas para que todas tenham o mesmo comprimento."
      ],
      "metadata": {
        "id": "nwCQ-o2fIpq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Pré-processamento\n",
        "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded_sequences = pad_sequences(sequences, padding=\"post\")"
      ],
      "metadata": {
        "id": "WOzlEZTYV4dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando a Arquitetura do Modelo\n",
        "\n",
        "Na criação do modelo vamos usar\n",
        "\n",
        "1. **Sequential:** Um modelo linear de camadas.\n",
        "O Sequential é a forma mais simples de criar um modelo no Keras/TensorFlow.\n",
        "Ele organiza as camadas de forma linear, ou seja, uma camada é conectada diretamente à próxima, como uma \"pilha\" de camadas. É ideal para problemas simples, onde os dados fluem de maneira ordenada entre as camadas, sem bifurcações ou junções complexas.\n",
        "\n",
        "2. **Embedding:** Camada que cria representações densas (embeddings) para as palavras. A camada Embedding converte palavras em vetores numéricos de tamanho fixo, chamados embeddings. Cada palavra é transformada em um vetor de números contínuos que representam características da palavra.\n",
        "\n",
        "3. `input_dim=1000`: Número máximo de palavras no vocabulário.\n",
        "Define o tamanho do vocabulário, ou seja, o número máximo de palavras únicas que o modelo consegue aprender. Se houver mais palavras, elas serão representadas pelo token <OOV> (Out Of Vocabulary).\n",
        "\n",
        "4. `output_dim=16`: Tamanho do vetor de cada palavra.\n",
        "É o tamanho dos vetores gerados para cada palavra. Neste caso, cada palavra é representada como um vetor de 16 números.\n",
        "Esse valor pode ser ajustado; tamanhos maiores capturam mais informações, mas tornam o modelo mais lento.\n",
        "\n",
        "5. `input_length`:\n",
        "É o comprimento máximo das sequências de entrada, usado para garantir compatibilidade entre os dados e a camada.\n",
        "\n",
        "6. `GlobalAveragePooling1D`: Reduz os embeddings a um vetor único.\n",
        "Após a camada Embedding, temos uma sequência de vetores (um vetor por palavra).\n",
        "O GlobalAveragePooling1D pega todos esses vetores e calcula a média deles, criando um único vetor final.\n",
        "Isso simplifica os dados e reduz a dimensão da entrada para as próximas camadas.\n",
        "\n",
        "  **Por que isso é útil?** Ele mantém uma representação global do texto (média das palavras), removendo a dependência do comprimento da frase.\n",
        "\n",
        "\n",
        "7.  Camada `Dense`:\n",
        "\n",
        "  a. 16 neurônios (ReLU): Camada oculta para aprendizado. A camada Dense conecta todos os neurônios da entrada com todos os neurônios da saída.\n",
        "\n",
        "  *   16 neurônios: Define o número de unidades (ou neurônios) nesta camada. Quanto mais neurônios, mais complexa será a representação aprendida.\n",
        "\n",
        "  *   Ativação ReLU: A função ReLU (Rectified Linear Unit) transforma as saídas negativas em zero e mantém as positivas. É amplamente utilizada em redes neurais por ser eficiente e reduzir o risco de saturação do modelo.A camada Dense conecta todos os neurônios da entrada com todos os neurônios da saída.\n",
        "  \n",
        "  b. neurônio (Sigmoid): Camada de saída que prevê probabilidade binária (positivo/negativo). Esta é a camada de saída do modelo.\n",
        "\n",
        "  * 1 neurônio signfica que a saída é um único valor, que será entre 0 e 1, devido à ativação da sigmoid.\n",
        "\n",
        "  * Ativação Sigmoid: A função sigmoide transforma a saída em uma probabilidade (número entre 0 e 1). Ela é ideal para problemas de classificação binária, onde o objetivo é prever \"positivo\" ou \"negativo\".\n",
        "\n",
        "\n",
        "8. Compilação do Modelo:\n",
        "\n",
        "  a. Otimizador: Adam\n",
        "  - O Adam (Adaptive Moment Estimation) é um dos otimizadores mais eficientes e populares em deep learning.\n",
        "  - Ele ajusta os pesos do modelo de forma adaptativa, acelerando o aprendizado e evitando que o modelo fique preso em mínimos locais.\n",
        "\n",
        "  b. Função de perda: Binary Crossentropy\n",
        "  - Binary Crossentropy mede a diferença entre as previsões do modelo e os rótulos reais.\n",
        "  - É a função ideal para problemas de classificação binária, penalizando previsões incorretas mais severamente.\n",
        "\n",
        "  c. Métrica: Acurácia\n",
        "  - A acurácia mede o percentual de previsões corretas feitas pelo modelo.\n",
        "  - É uma métrica intuitiva para entender o desempenho do modelo em tarefas de classificação binária."
      ],
      "metadata": {
        "id": "ssUUTepBI6CF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Criação do modelo\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=1000, output_dim=16, input_length=padded_sequences.shape[1]),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "St4jZoixV5wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167aaf78-5341-4f09-a1cf-3d4f7d78c863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Treinamento do Modelo\n",
        "\n",
        "- Conversão dos dados: Garante que as sequências e rótulos estejam no formato correto (float32).\n",
        "- Treinamento:\n",
        "  - epochs=10: O modelo passa pelos dados 10 vezes.\n",
        "  - verbose=0: Supressão da saída de progresso para visualização mais limpa.\n"
      ],
      "metadata": {
        "id": "yayXcXBqM3r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Treinamento\n",
        "# Convert padded_sequences and labels to NumPy arrays with dtype=float32\n",
        "padded_sequences = padded_sequences.astype('float32')\n",
        "labels = tf.convert_to_tensor(labels, dtype=tf.float32) # or labels = np.array(labels, dtype=np.float32)\n",
        "\n",
        "model.fit(padded_sequences, labels, epochs=10, verbose=0)\n"
      ],
      "metadata": {
        "id": "cTvXEtO3V7IK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30b72f7-5330-4a55-e741-94fc73d6f531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ccb56c7d960>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O model.summary() é uma função do Keras que fornece um resumo da arquitetura do seu modelo. Com ela obtemos uma representação visual da estrutura do classificador de sentimentos, mostrando como as camadas estão conectadas, seus parâmetros e o formato dos dados à medida que passam pelo modelo."
      ],
      "metadata": {
        "id": "4wSfbne_PYs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "YDqFsWupOzAk",
        "outputId": "48bf3563-45c2-4bfc-9fe4-cdfab33eff79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)               │          \u001b[38;5;34m16,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,869\u001b[0m (190.90 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,869</span> (190.90 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,289\u001b[0m (63.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,289</span> (63.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m32,580\u001b[0m (127.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,580</span> (127.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando o Modelo e Resultados\n",
        "\n",
        "- Entrada de teste: Uma nova frase para prever o sentimento.\n",
        "- `texts_to_sequences`: Transforma a frase em tokens usando o mesmo tokenizer treinado.\n",
        "- `pad_sequences`: Ajusta o tamanho da sequência para o mesmo valor usado durante o treinamento.\n",
        "\n",
        "- Predição:\n",
        " - O modelo retorna um valor entre 0 e 1.\n",
        " - Se > 0.5: Considera positivo se a probabilidade for maior que 50%.\n",
        "\n",
        "- Resultado: O sentimento é exibido como \"Positivo\" ou \"Negativo\"."
      ],
      "metadata": {
        "id": "uW1pNvpBNK7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Testando o modelo\n",
        "test_sentence = [\"Eu amo pizza!\"]\n",
        "test_seq = tokenizer.texts_to_sequences(test_sentence)\n",
        "test_pad = pad_sequences(test_seq, maxlen=padded_sequences.shape[1])\n",
        "# Convert test_pad to float32\n",
        "test_pad = test_pad.astype('float32')\n",
        "prediction = model.predict(test_pad)[0][0]"
      ],
      "metadata": {
        "id": "NTvwIE_GV8c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497062db-873b-4062-b29a-791270fe0d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimindo prediction para conferência\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCIlVziHUKrC",
        "outputId": "5126c642-596c-4a21-dfbc-27cf99d2cecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5001468"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sentimento: {'Positivo' if prediction > 0.50 else 'Negativo'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Q0l_JPTsJL",
        "outputId": "75f96f83-ff0e-42eb-d571-01930605412c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimento: Positivo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado Final\n",
        "\n",
        "O modelo consegue prever o sentimento da frase usando deep learning com TensorFlow. Este exemplo simples mostra como é possível criar um classificador de texto com poucas linhas de código! 🚀\n",
        "\n",
        "O modelo que criamos consegue prever o sentimento de uma frase, distinguindo entre positivo e negativo, com base em padrões aprendidos durante o treinamento. Ele faz isso utilizando deep learning com TensorFlow, aproveitando representações numéricas (embeddings) e redes neurais para processar o texto de forma eficiente e precisa.\n",
        "\n",
        "Apesar de ser um exemplo simples, ele demonstra como é possível construir um classificador de texto básico com apenas algumas linhas de código. Ferramentas como TensorFlow tornam acessível a implementação de algoritmos complexos de aprendizado profundo, permitindo que mesmo iniciantes comecem a explorar o mundo da inteligência artificial aplicada a texto."
      ],
      "metadata": {
        "id": "AAmJJ7k_RavE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aeMX362ORc3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}